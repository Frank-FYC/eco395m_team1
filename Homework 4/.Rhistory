# attach the predictions to the test data frame
D_test$ypred_lm2 = ypred_lm2
D_test$ypred_knn250 = ypred_knn250
p_test = ggplot(data = D_test) +
geom_point(mapping = aes(x = KHOU, y = COAST), color='lightgrey') +
theme_bw(base_size=18) +
ylim(7000, 20000)
p_test
p_test + geom_point(aes(x = KHOU, y = ypred_knn250), color='red')
p_test + geom_path(aes(x = KHOU, y = ypred_knn250), color='red')
p_test + geom_path(aes(x = KHOU, y = ypred_knn250), color='red') +
geom_path(aes(x = KHOU, y = ypred_lm2), color='blue')
N
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
n
N
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
N
loadhou = loadhou[sample(nrow(loadhou), 150), ]
loadhou
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
loadhou = loadhou[sample.int(nrow(loadhou), 150), replace=FALSE]
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
loadhou_sample = loadhou[sample.int(nrow(loadhou), 150), ]
loadhou_sample
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/2019-02-06 Class/in-class exercise.R', echo=TRUE)
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/eco395m_team_awesome/Homework 4/playlists.R', echo=TRUE)
setwd("C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/eco395m_team_awesome/Homework 4")
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/eco395m_team_awesome/Homework 4/playlists.R', echo=TRUE)
summary(playtrans)
# Look at the output... so many rules!
inspect(musicrules)
## Remove duplicates ("de-dupe")
# lapply says "apply a function to every element in a list"
basket = lapply(basket, unique)
library(tidyverse)
library(arules)  # has a big ecosystem of packages built around it
library(arulesViz)
# Association rule mining
groceries <- read.csv("groceries.txt", header=FALSE)
names(groceries)
str(groceries)
summary(groceries)
# Barplot of top grocery lists
# Cool use of magrittr pipes (%>%) in plotting/summary workflow
groceries$V1 %>%
summary(maxsum=Inf) %>%
sort(decreasing=TRUE) %>%
head(20) %>%
barplot(las=2, cex.names=0.6)
# First create a list of baskets: vectors of items by first item
# apriori algorithm expects a list of baskets in a special format
# In this case, one "basket" of songs per user
# First split data into a list of artists for each user
basket = split(x=groceries$V1, f=groceries$V2)
# the first users's playlist, the second user's etc
# note the [[ ]] indexing, this is how you extract
# numbered elements of a list in R
basket[[1]]
basket[[2]]
## Remove duplicates ("de-dupe")
# lapply says "apply a function to every element in a list"
basket = lapply(basket, unique)
## Cast this variable as a special arules "transactions" class.
basket.trans = as(basket, "transactions")
summary(basket.trans)
length(basket)
basket.rules = apriori(basket.trans, parameter=list(support=.01, confidence=.1, maxlen=4))
# Now run the 'apriori' algorithm
# Look at rules with support > .01 & confidence >.1 & length (# items) <= 4
basket.rules = apriori(basket.trans, parameter=list(support=.1, confidence=.2, maxlen=4))
# plot all the rules in (support, confidence) space
# notice that high lift rules tend to have low support
plot(basket.rules)
# can swap the axes and color scales
plot(basket.rules, measure = c("support", "lift"), shading = "confidence")
# "two key" plot: coloring is by size (order) of item set
plot(basket.rules, method='two-key plot')
# can now look at subsets driven by the plot
inspect(subset(basket.rules, support > 0.035))
# graph-based visualization
sub1 = subset(basket.rules, subset=confidence > 0.01 & support > 0.005)
# graph-based visualization
sub1 = subset(basket.rules, subset=confidence > 0.3 & support > 0.2)
summary(sub1)
plot(sub1, method='graph')
plot(head(sub1, 100, by='lift'), method='graph')
# export a graph
saveAsGraph(sub1, file = "basket_rules.graphml")
View(sub1)
head(sub1)
sub1 = subset(basket.rules, subset=confidence > 0.3 & support > 0.2)
summary(sub1)
plot(sub1, method='graph')
#?plot.rules
plot(head(sub2, 100, by='lift'), method='graph')
# export a graph
saveAsGraph(sub2, file = "basket_rules.graphml")
sub1 = subset(musicrules, subset=confidence > 0.01 & support > 0.005)
summary(sub1)
plot(sub1, method='graph')
?plot.rules
plot(head(sub1, 100, by='lift'), method='graph')
# export a graph
saveAsGraph(sub1, file = "musicrules.graphml")
head(sub1)
view(sub1)
View(basket)
basket = names(item1,item2,item3,item4)
names(data) <- c("item1","item2","item3","item4")
names(groceries)
names(groceries) <- c("item1","item2","item3","item4")
View(groceries)
View(playlists_raw)
groceries_raw <- read.csv("groceries.txt", header=FALSE)
names(groceries_raw) <- c("item1","item2","item3","item4")
groceries <- gather(groceries_raw)
View(groceries)
View(groceries_raw)
setDT(groceries_raw, keep.rownames = "id")[]
library(data.table)
groceries_raw <- read.csv("groceries.txt", header=FALSE)
setDT(groceries_raw, keep.rownames = "id")[]
View(playlists_raw)
View(groceries_raw)
names(groceries_raw) <- c("id","item1","item2","item3","item4")
groceries <- gather(groceries_raw)
View(groceries)
groceries <- gather(groceries_raw,id,item,item1:item4,factor_key = TRUE)
View(groceries)
groceries <- gather(groceries_raw,condition,measurement,item1:item4,factor_key = TRUE)
View(groceries)
groceries <- gather(groceries_raw,xyz,measurement,item1:item4,factor_key = TRUE)
View(groceries)
groceries <- gather(groceries_raw,order,item,item1:item4,factor_key = TRUE)
View(groceries)
groceries$id %>%
summary(maxsum=Inf) %>%
sort(decreasing=TRUE) %>%
head(20) %>%
barplot(las=2, cex.names=0.6)
groceries$order %>%
summary(maxsum=Inf) %>%
sort(decreasing=TRUE) %>%
head(20) %>%
barplot(las=2, cex.names=0.6)
groceries$item %>%
summary(maxsum=Inf) %>%
sort(decreasing=TRUE) %>%
head(20) %>%
barplot(las=2, cex.names=0.6)
groceries %>%
summary(maxsum=Inf) %>%
sort(decreasing=TRUE) %>%
head(20) %>%
barplot(las=2, cex.names=0.6)
groceries_raw$item1 %>%
summary(maxsum=Inf) %>%
sort(decreasing=TRUE) %>%
head(20) %>%
barplot(las=2, cex.names=0.6)
# apriori algorithm expects a list of baskets in a special format
# In this case, one "basket" of songs per user
# First split data into a list of artists for each user
basket = split(x=groceries$item, f=groceries$id)
# the first users's playlist, the second user's etc
# note the [[ ]] indexing, this is how you extract
# numbered elements of a list in R
basket[[1]]
basket[[2]]
## Remove duplicates ("de-dupe")
# lapply says "apply a function to every element in a list"
basket = lapply(basket, unique)
## Cast this variable as a special arules "transactions" class.
basket.trans = as(basket, "transactions")
summary(basket.trans)
# Now run the 'apriori' algorithm
# Look at rules with support > .01 & confidence >.1 & length (# items) <= 4
basket.rules = apriori(basket.trans, parameter=list(support=.1, confidence=.2, maxlen=4))
# plot all the rules in (support, confidence) space
# notice that high lift rules tend to have low support
plot(basket.rules)
# Now run the 'apriori' algorithm
# Look at rules with support > .01 & confidence >.1 & length (# items) <= 4
basket.rules = apriori(basket.trans, parameter=list(support=.01, confidence=.1, maxlen=4))
# plot all the rules in (support, confidence) space
# notice that high lift rules tend to have low support
plot(basket.rules)
# Now run the 'apriori' algorithm
# Look at rules with support > .01 & confidence >.1 & length (# items) <= 4
basket.rules = apriori(basket.trans, parameter=list(support=.001, confidence=.01, maxlen=4))
# plot all the rules in (support, confidence) space
# notice that high lift rules tend to have low support
plot(basket.rules)
# plot all the rules in (support, confidence) space
# notice that high lift rules tend to have low support
plot(basket.rules)
# can swap the axes and color scales
plot(basket.rules, measure = c("support", "lift"), shading = "confidence")
# "two key" plot: coloring is by size (order) of item set
plot(basket.rules, method='two-key plot')
# graph-based visualization
sub1 = subset(basket.rules, subset=confidence > 0.3 & support > 0.2)
summary(sub2)
plot(sub2, method='graph')
plot(head(sub2, 100, by='lift'), method='graph')
# export a graph
saveAsGraph(sub2, file = "basket_rules.graphml")
# graph-based visualization
sub2 = subset(basket.rules, subset=confidence > 0.3 & support > 0.2)
summary(sub2)
plot(sub2, method='graph')
plot(head(sub2, 100, by='lift'), method='graph')
# export a graph
saveAsGraph(sub2, file = "basket_rules.graphml")
# graph-based visualization
sub2 = subset(basket.rules, subset=confidence > 0.3 & support > 0.2)
summary(sub2)
plot(head(sub2, 100, by='lift'), method='graph')
plot(head(sub2, 100, by='lift'), method='graph')
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/eco395m_team_awesome/Homework 4/question 3.R', echo=TRUE)
# "two key" plot: coloring is by size (order) of item set
plot(basket.rules, method='two-key plot')
# graph-based visualization
#sub2 = subset(basket.rules, subset=confidence > 0.3 & support > 0.2)
#summary(sub2)
plot(basket.rules, method='graph')
plot(head(basket.rules, 100, by='lift'), method='graph')
# export a graph
saveAsGraph(basket.rules, file = "basket_rules.graphml")
# graph-based visualization
sub2 = subset(basket.rules, subset=confidence > 0.1 & support > 0.01)
plot(head(sub2, 100, by='lift'), method='graph')
# export a graph
saveAsGraph(sub2, file = "basket_rules.graphml")
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/eco395m_team_awesome/Homework 4/question 3.R', echo=TRUE)
summary(groceries)
summary(groceries_raw)
library(tidyverse)
library(arules)  # has a big ecosystem of packages built around it
library(arulesViz)
library(data.table)
# Association rule mining
groceries_raw <- read.csv("groceries.txt", header=FALSE)
setDT(groceries_raw, keep.rownames = "id")[]
names(groceries_raw) <- c("id","item1","item2","item3","item4")
groceries <- gather(groceries_raw,order,item,item1:item4,factor_key = TRUE)
groceries_raw$item1 %>%
summary(maxsum=Inf) %>%
sort(decreasing=TRUE) %>%
head(20) %>%
barplot(las=2, cex.names=0.6)
groceries_raw$item1 %>%
summary(maxsum=Inf) %>%
sort(decreasing=TRUE) %>%
head(20) %>%
barplot(las=2, cex.names=0.6)
plot(basket.rules)
plot(basket.rules)
plot(basket.rules)
plot(basket.rules, measure = c("support", "lift"), shading = "confidence")
plot(basket.rules, method='two-key plot')
plot(basket.rules)
plot(basket.rules, measure = c("support", "lift"), shading = "confidence")
plot(basket.rules, method='two-key plot')
plot(basket.rules, method='graph')
plot(basket.rules, method='graph',comment=FALSE)
plot(basket.rules)
plot(basket.rules, measure = c("support", "lift"), shading = "confidence")
plot(basket.rules, method='two-key plot')
suppresswarnings(plot(basket.rules, method='graph',comment=FALSE))
plot(basket.rules)
plot(basket.rules, measure = c("support", "lift"), shading = "confidence")
plot(basket.rules, method='two-key plot')
suppressWarnings(plot(basket.rules, method='graph',comment=FALSE))
par(mfrow=c(3,1))
plot(basket.rules)
plot(basket.rules, measure = c("support", "lift"), shading = "confidence")
plot(basket.rules, method='two-key plot')
install.packages("svglite")
knitr::opts_chunk$set(echo = TRUE)
library(svglite)
knitr::opts_chunk$set(
dev = "svglite",
fig.ext = ".svg"
)
svglite::svglite("gephi_export.svg")
svglite::svglite("gephi_export.svg")
svglite::svglite("myfile.svg")
test <- svglite::svglite("myfile.svg")
test
test <- svglite::svglite("gephi_export.svg")
test
plot(runif(10), runif(10))
dev.off()
test <- svglite("gephi_export.svg")
plot(runif(10), runif(10))
dev.off()
plot(basket.rules, method='two-key plot')
groceries_raw$item1 %>%
summary(maxsum=Inf) %>%
sort(decreasing=TRUE) %>%
head(20) %>%
barplot(las=2, cex.names=0.6)
knitr::opts_chunk$set(echo = TRUE)
library(svglite)
knitr::opts_chunk$set(
dev = "svglite",
fig.ext = ".svg"
)
library(ISLR)
library(tidyverse)
library(ggplot2)
library(psych)
library(xtable)
wine <- read.csv("wine.csv", header = TRUE)
# Pick out the pca columns
Z = wine[,c(1:9)]
# Standardize (center/scale) the data
Z_std = scale(Z, center=TRUE, scale=TRUE)
plot(Z_std)
x_wine = as.matrix(wine[,1:11])
y_wine_quality= wine[,12]
y_wine_color= wine[,13]
# Let's try dimensionality reduction via PCA
pc_wine = prcomp(x_wine, scale=TRUE)
# pc_wine$x has the summary variables
# Regress on the first K
K = 3
scores = pc_wine$x[,1:K]
pcr1 = lm(y_wine_quality ~ scores)
print(xtable(summary(pcr1)),comment=FALSE)
# fancy plot matrix with stuff, see http://www.sthda.com/english/wiki/scatter-plot-matrices-r-base-graphs
pairs.panels(Z_std[,1:6],
method = "pearson", # correlation method
hist.col = "#00AFBB",
density = TRUE,  # show density plots
ellipses = TRUE # show correlation ellipses
)
# Show the model fit
par(mfrow=c(2,2))
plot(fitted(pcr1), y_wine_quality, main="Wine Quality and PC 1", ylab = "Wine Quality",xlab = "Estimated Wine Quality from PCA")
plot(seq(1,11,by=1), pc_wine$rotation[,1], main="Coefficients of PC 1", ylab = "PC 1 Effects",xlab = "PC Input Variables")
plot(seq(1,11,by=1), pc_wine$rotation[,2], main="Coefficients of PC 2", ylab = "PC 2 Effects",xlab = "PC Input Variables")
plot(seq(1,11,by=1), pc_wine$rotation[,3], main="Coefficients of PC 3", ylab = "PC 3 Effects",xlab = "PC Input Variables")
library(ggplot2)
library(LICORS)  # for kmeans++
library(foreach)
library(mosaic)
library(gridExtra)
library(grid)
# Center and scale the data
X = wine[,c(1:9)]
X = scale(X, center=TRUE, scale=TRUE)
# Extract the centers and scales from the rescaled data (which are named attributes)
mu = attr(X,"scaled:center")
sigma = attr(X,"scaled:scale")
# Run k-means with 2 clusters and 25 starts
clust1 = kmeans(X, 2, nstart=25)
# Using kmeans++ initialization
clust2 = kmeanspp(X, k=2, nstart=25)
# What are the clusters?
print("Cluster 1")
clust2$center[1,]*sigma + mu
print("Cluster 2")
clust2$center[2,]*sigma + mu
qplot(fixed.acidity, volatile.acidity, data=wine, color=factor(clust2$cluster),main = "Volatile and Fixed Acidity by Wine Type")+
labs(colour = "Wine Type")
qplot(citric.acid, residual.sugar, data=wine, color=factor(clust2$cluster),main = "Citric Acid and Residual Sugar by Wine Type by Wine Type")+
labs(colour = "Wine Type")
qplot(quality, color, data=wine, color=factor(clust2$cluster),main = "Wine Qualiy and Color by actual Wine Type")+
labs(colour = "Wine Type")
library(tidyverse)
library(arules)  # has a big ecosystem of packages built around it
library(arulesViz)
library(data.table)
# Association rule mining
groceries_raw <- read.csv("groceries.txt", header=FALSE)
setDT(groceries_raw, keep.rownames = "id")[]
names(groceries_raw) <- c("id","item1","item2","item3","item4")
groceries <- gather(groceries_raw,order,item,item1:item4,factor_key = TRUE)
basket = split(x=groceries$item, f=groceries$id)
basket = lapply(basket, unique)
basket.trans = as(basket, "transactions")
basket.rules = apriori(basket.trans, parameter=list(support=.001, confidence=.01, maxlen=4))
sub2 = subset(basket.rules, subset=confidence > 0.1 & support > 0.01)
groceries_raw$item1 %>%
summary(maxsum=Inf) %>%
sort(decreasing=TRUE) %>%
head(20) %>%
barplot(las=2, cex.names=0.6)
par(mfrow=c(3,1))
plot(basket.rules)
plot(basket.rules, measure = c("support", "lift"), shading = "confidence")
plot(basket.rules, method='two-key plot')
svglite::svglite("gephi_export.svg")
?dev.off
plot(runif(10), runif(10))
test <- svglite("gephi_export.svg")
test
test <- htmlSVG("gephi_export.svg")
test
test <- svglite("gephi_export.svg")
test
test <- htmlSVG("gephi_export.svg")
test
![Market Basket Association Network](C:\Dropbox\Classes\ECO 395M Data mining and statisical learning\eco395m_team_awesome\Homework 4)
knitr::include_graphics("gephi_export.png")
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
library(tidyverse)
library(ggplot2)
library(psych)
library(xtable)
wine <- read.csv("wine.csv", header = TRUE)
# Pick out the pca columns
Z = wine[,c(1:9)]
# Standardize (center/scale) the data
Z_std = scale(Z, center=TRUE, scale=TRUE)
plot(Z_std)
x_wine = as.matrix(wine[,1:11])
y_wine_quality= wine[,12]
y_wine_color= wine[,13]
# Let's try dimensionality reduction via PCA
pc_wine = prcomp(x_wine, scale=TRUE)
# pc_wine$x has the summary variables
# Regress on the first K
K = 3
scores = pc_wine$x[,1:K]
pcr1 = lm(y_wine_quality ~ scores)
print(xtable(summary(pcr1)),comment=FALSE)
# fancy plot matrix with stuff, see http://www.sthda.com/english/wiki/scatter-plot-matrices-r-base-graphs
pairs.panels(Z_std[,1:6],
method = "pearson", # correlation method
hist.col = "#00AFBB",
density = TRUE,  # show density plots
ellipses = TRUE # show correlation ellipses
)
# Show the model fit
par(mfrow=c(2,2))
plot(fitted(pcr1), y_wine_quality, main="Wine Quality and PC 1", ylab = "Wine Quality",xlab = "Estimated Wine Quality from PCA")
plot(seq(1,11,by=1), pc_wine$rotation[,1], main="Coefficients of PC 1", ylab = "PC 1 Effects",xlab = "PC Input Variables")
plot(seq(1,11,by=1), pc_wine$rotation[,2], main="Coefficients of PC 2", ylab = "PC 2 Effects",xlab = "PC Input Variables")
plot(seq(1,11,by=1), pc_wine$rotation[,3], main="Coefficients of PC 3", ylab = "PC 3 Effects",xlab = "PC Input Variables")
library(ggplot2)
library(LICORS)  # for kmeans++
library(foreach)
library(mosaic)
library(gridExtra)
library(grid)
# Center and scale the data
X = wine[,c(1:9)]
X = scale(X, center=TRUE, scale=TRUE)
# Extract the centers and scales from the rescaled data (which are named attributes)
mu = attr(X,"scaled:center")
sigma = attr(X,"scaled:scale")
# Run k-means with 2 clusters and 25 starts
clust1 = kmeans(X, 2, nstart=25)
# Using kmeans++ initialization
clust2 = kmeanspp(X, k=2, nstart=25)
# What are the clusters?
print("Cluster 1")
clust2$center[1,]*sigma + mu
print("Cluster 2")
clust2$center[2,]*sigma + mu
qplot(fixed.acidity, volatile.acidity, data=wine, color=factor(clust2$cluster),main = "Volatile and Fixed Acidity by Wine Type")+
labs(colour = "Wine Type")
qplot(citric.acid, residual.sugar, data=wine, color=factor(clust2$cluster),main = "Citric Acid and Residual Sugar by Wine Type by Wine Type")+
labs(colour = "Wine Type")
qplot(quality, color, data=wine, color=factor(clust2$cluster),main = "Wine Qualiy and Color by actual Wine Type")+
labs(colour = "Wine Type")
library(tidyverse)
library(arules)  # has a big ecosystem of packages built around it
library(arulesViz)
library(data.table)
# Association rule mining
groceries_raw <- read.csv("groceries.txt", header=FALSE)
setDT(groceries_raw, keep.rownames = "id")[]
names(groceries_raw) <- c("id","item1","item2","item3","item4")
groceries <- gather(groceries_raw,order,item,item1:item4,factor_key = TRUE)
basket = split(x=groceries$item, f=groceries$id)
basket = lapply(basket, unique)
basket.trans = as(basket, "transactions")
basket.rules = apriori(basket.trans, parameter=list(support=.001, confidence=.01, maxlen=4))
sub2 = subset(basket.rules, subset=confidence > 0.1 & support > 0.01)
groceries_raw$item1 %>%
summary(maxsum=Inf) %>%
sort(decreasing=TRUE) %>%
head(20) %>%
barplot(las=2, cex.names=0.6)
par(mfrow=c(3,1))
plot(basket.rules)
plot(basket.rules, measure = c("support", "lift"), shading = "confidence")
plot(basket.rules, method='two-key plot')
knitr::include_graphics("gephi_export.png")
view(basket.rules)
View(title@quality)
View(title@quality)
