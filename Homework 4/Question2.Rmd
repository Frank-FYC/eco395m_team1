---
title: "Q2 RMD"
author: "Tejaswi Pukkalla"
date: "April 26, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question 2: Market Segmentation

Our objective is to help NutrientH2O understand its social-media audience a little better, so it could work on targeting its market segment more aptly. We start off the same way we start any data analysis, cleaning up the data first. We try our best to clear out out the bots that might have slipped through the initial filtering. We delete users marked as spam. We measure the amount of adult content in the user's messages and delete users that have more than a quarter of their messages flagged as adult content. After removing the unused attributes now that we have deleted users with non zero values in those attributes, we move on to centering and scaling the data. 

```{r libraries, echo=FALSE, warning=FALSE, include=FALSE}
library(foreach)
library(cluster)
library(corrplot)
library(plotly)
library(GGally)
library(HSAUR)


#36 different categories
SocialData <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/social_marketing.csv", row.names=1)

#delete users with spam
SocialData<-SocialData[(SocialData$spam==0),]

#delete uncategorized label "chatter"
SocialData <- subset(SocialData, select = -c(chatter, uncategorized))

#add total tweets & calculate adult ratio & delete adult ratio more than 30%
SocialData <- cbind(tot_twt = rowSums(SocialData), SocialData)
SocialData <- cbind(adult_ratio = 1, SocialData)
SocialData$adult_ratio <- SocialData$adult/SocialData$tot_twt
SocialData<-SocialData[(SocialData$adult_ratio<0.3),]

#delete uncategorized label "unused attributes"
SocialData <- subset(SocialData, select = -c(adult_ratio, tot_twt, spam))

# Center/scale the data
SocialData_scaled <- scale(SocialData, center=TRUE, scale=TRUE) 
```

We first use K-means clustering to measure the SSE error and check the various values of SSE error for different values of K.

```{r SSE, echo=FALSE, warning=FALSE}
#K-grid to find the optimal K
k_grid = seq(2, 20, by=1)
SSE_grid = foreach(k = k_grid, .combine='c') %do% {
  cluster_k = kmeans(SocialData_scaled, k, nstart=50)
  cluster_k$tot.withinss
}
plot(k_grid, SSE_grid, xlab="K",ylab="SSE Grid", sub="SSE Grid vs K")
```

Next we use K-means clustering again, but this time we measure the CH grid values for their respective K values.

```{r CH, echo=FALSE, warning=FALSE}
#CH-grid to find the optimal K
N=nrow(SocialData)
CH_grid = foreach(k = k_grid, .combine='c') %do% {
  cluster_k = kmeans(SocialData_scaled, k, nstart=20)
  W = cluster_k$tot.withinss
  B = cluster_k$betweenss
  CH = (B/W)*((N-k)/(k-1))
  CH
}
plot(k_grid, CH_grid, xlab="K",
     ylab="CH Grid",
     sub="CH Grid vs K")
```

Next, we use the cluster gap function to see where the dip in cluster gap is.

```{r CG, echo=FALSE, warning=FALSE}
#Gap statistics
Market_gap = clusGap(SocialData_scaled, FUN = kmeans, nstart = 20, K.max = 10, B = 10)
plot(Market_gap)
```

From the above plots, we chose K=6 intuitively as the optimum K value. There is a slight dip in the CH Grid Vs K graph at K=6. However, there is no clear dip in Cluster gaop at all showing this isn't a convex cluster.  

To analyse the K-means clustering, let's first take a look into the correlation between these various post indicators/factors.

```{r COR, echo=FALSE, warning=FALSE}
#correlation and visualization
corr <- cor(SocialData_scaled)
corrplot(corr, method="color", type="upper", tl.cex = 0.5, tl.col="black", order="hclust")
```

\pagebreak

From the above graph, we pick the factors that have highest correlation with each other and try to analyze the K-means clustering results of these factors.

i) Personal fitness, Health, Outdoors

```{r D1, echo=FALSE, warning=FALSE}
# k-means analysis
clust1 = kmeans(SocialData_scaled, centers=6, nstart=25)
D1 = subset(SocialData,select = c("personal_fitness","health_nutrition","outdoors"))
ggpairs(D1, aes(col = factor(clust1$cluster), alpha=0.5), columns = 1:ncol(D1), title = "Clusters on personal fitness, health and outdoors",
        upper = list(continuous = "cor", combo = "box_no_facet", discrete = "facetbar", na = "na"), 
        lower = list(continuous = "points", combo = "facethist", discrete = "facetbar", na = "na"), 
        diag = list(continuous =  "densityDiag", discrete = "barDiag", na = "naDiag"), params = NULL,
        xlab = NULL, ylab = NULL, axisLabels = c("show"),
        labeller = "label_value",
        switch = NULL, showStrips = NULL, legend = NULL,
        cardinality_threshold = 15, progress = NULL)
```

\pagebreak

ii) Fashion, Cooking, Beauty, Shopping, Photo sharing

```{r D2, echo=FALSE, warning=FALSE}
D2 = subset(SocialData,select = c("fashion","cooking","beauty", "shopping", "photo_sharing"))
ggpairs(D2, aes(col = factor(clust1$cluster), alpha=0.5), columns = 1:ncol(D1), title = "Clusters on fashion, cooking, beauty, shopping and photosharing",
        upper = list(continuous = "cor", combo = "box_no_facet", discrete = "facetbar", na = "na"), 
        lower = list(continuous = "points", combo = "facethist", discrete = "facetbar", na = "na"), 
        diag = list(continuous =  "densityDiag", discrete = "barDiag", na = "naDiag"), params = NULL,
        xlab = NULL, ylab = NULL, axisLabels = c("show"),
        labeller = "label_value",
        switch = NULL, showStrips = NULL, legend = NULL,
        cardinality_threshold = 15, progress = NULL)
```

\pagebreak

iii) Gaming, College, Sports

```{r D3, echo=FALSE, warning=FALSE}
D3 = subset(SocialData,select = c("online_gaming","college_uni","sports_playing"))
ggpairs(D3, aes(col = factor(clust1$cluster), alpha=0.5), columns = 1:ncol(D1), title = "Clusters on gaming, university and sports",
        upper = list(continuous = "cor", combo = "box_no_facet", discrete = "facetbar", na = "na"), 
        lower = list(continuous = "points", combo = "facethist", discrete = "facetbar", na = "na"), 
        diag = list(continuous =  "densityDiag", discrete = "barDiag", na = "naDiag"), params = NULL,
        xlab = NULL, ylab = NULL, axisLabels = c("show"),
        labeller = "label_value",
        switch = NULL, showStrips = NULL, legend = NULL,
        cardinality_threshold = 15, progress = NULL)
```

\pagebreak

iv) Sports fan, Parenting, School, Food, Family

```{r D4, echo=FALSE, warning=FALSE}
D4 = subset(SocialData,select = c("sports_fandom","parenting","school","food", "family"))
ggpairs(D4, aes(col = factor(clust1$cluster), alpha=0.5), columns = 1:ncol(D1), title = "Clusters on sports, parenting, school, food, family",
        upper = list(continuous = "cor", combo = "box_no_facet", discrete = "facetbar", na = "na"), 
        lower = list(continuous = "points", combo = "facethist", discrete = "facetbar", na = "na"), 
        diag = list(continuous =  "densityDiag", discrete = "barDiag", na = "naDiag"), params = NULL,
        xlab = NULL, ylab = NULL, axisLabels = c("show"),
        labeller = "label_value",
        switch = NULL, showStrips = NULL, legend = NULL,
        cardinality_threshold = 15, progress = NULL)
```

\pagebreak

v) Politics, News, Computers, Travel, Automotive

```{r D5, echo=FALSE, warning=FALSE}
D5 = subset(SocialData,select = c("politics","news","computers", "travel", "automotive"))
ggpairs(D5, aes(col = factor(clust1$cluster), alpha=0.5), columns = 1:ncol(D1), title = "Clusters on politics, news, computers, travel, automotive",
        upper = list(continuous = "cor", combo = "box_no_facet", discrete = "facetbar", na = "na"), 
        lower = list(continuous = "points", combo = "facethist", discrete = "facetbar", na = "na"), 
        diag = list(continuous =  "densityDiag", discrete = "barDiag", na = "naDiag"), params = NULL,
        xlab = NULL, ylab = NULL, axisLabels = c("show"),
        labeller = "label_value",
        switch = NULL, showStrips = NULL, legend = NULL,
        cardinality_threshold = 15, progress = NULL)
```

\pagebreak

vi) TV, Art, Music

```{r D6, echo=FALSE, warning=FALSE}
D6 = subset(SocialData,select = c("tv_film","art","music"))
ggpairs(D6, aes(col = factor(clust1$cluster), alpha=0.5), columns = 1:ncol(D1), title = "Clusters on tv, art, music",
        upper = list(continuous = "cor", combo = "box_no_facet", discrete = "facetbar", na = "na"), 
        lower = list(continuous = "points", combo = "facethist", discrete = "facetbar", na = "na"), 
        diag = list(continuous =  "densityDiag", discrete = "barDiag", na = "naDiag"), params = NULL,
        xlab = NULL, ylab = NULL, axisLabels = c("show"),
        labeller = "label_value",
        switch = NULL, showStrips = NULL, legend = NULL,
        cardinality_threshold = 15, progress = NULL)
```

From the above graphs, we can see that there isn't much we can try to extract in terms of segments from the above data. Very few factors are highly explained by other factors. Hence, we decided to do the PCA analysis to extract them into different market segments so that we can see what are the factors explaining the most amount of the variance in their messages. As we have done multiple edits to the original dataset, we again extract the original dataset from the website and clean it up again using the same criterion as before. 

```{r PCA, echo=FALSE, warning=FALSE, include=FALSE}
SocialMarket <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/social_marketing.csv", row.names=1)

#delete users with spam
SocialMarket<-SocialMarket[(SocialMarket$spam==0),]

#delete uncategorized label "chatter"
SocialMarket <- subset(SocialMarket, select = -c(chatter, uncategorized))

#add total tweets & calculate adult ratio & delete adult ratio more than 30%
SocialMarket <- cbind(tot_twt = rowSums(SocialMarket), SocialMarket)
SocialMarket <- cbind(adult_ratio = 1, SocialMarket)
SocialMarket$adult_ratio <- SocialMarket$adult/SocialMarket$tot_twt
SocialMarket<-SocialMarket[(SocialMarket$adult_ratio<0.3),]

#delete uncategorized label "unused attributes"
SocialMarket <- subset(SocialMarket, select = -c(adult_ratio, tot_twt, spam))

#center and scale the data
SocialMarket = scale(SocialMarket, center=TRUE, scale=TRUE)

# correlation
corr=cor(SocialMarket)

# PCA
pca = prcomp(SocialMarket,scale=TRUE)
loadings = pca$rotation
scores = pca$x

# PVE
V = pca$sdev^2
PVE = V / sum(V)
round(PVE, 2)
```

After doing the PCA analysis of the data and calculating both variance and the proportion of variance explained by these low dimensional summaries, we plot the Scree plot and the cumulative scree plot to get an idea on the different segments explaining these differences. 

```{r Scree Plot, echo=FALSE, warning=FALSE}
Plot1 = qplot(c(1:33), PVE) + 
  geom_line() + 
  xlab("Principal Component") + 
  ylab("PVE") +
  ggtitle("Scree Plot") +
  ylim(0, 0.15)
Plot1
```

```{r CSP, echo=FALSE, warning=FALSE}
Plot2 = qplot(c(1:33), cumsum(PVE)) + 
  geom_line() + 
  xlab("Principal Component") + 
  ylab(NULL) +
  ggtitle("Cumulative Scree Plot") +
  ylim(0,1)
Plot2
```

From the above graphs, we can see that almost 50% of the variance is explained by the 6 out of 33 factors. Hence, this reaffirms our intiial value of K as well. We get the following market segments that NutrientH2O can use to segment its audience and target them with sharper messages.

```{r ES, echo=FALSE, warning=FALSE, include=FALSE}
# extract market segments
o1 = order(loadings[,1], decreasing=TRUE)
colnames(SocialMarket)[head(o1,5)]
o2 = order(loadings[,2], decreasing=TRUE)
colnames(SocialMarket)[head(o2,5)]
o3 = order(loadings[,3], decreasing=TRUE)
colnames(SocialMarket)[head(o3,5)]
o4 = order(loadings[,4], decreasing=TRUE)
colnames(SocialMarket)[head(o4,5)]
o5 = order(loadings[,5], decreasing=TRUE)
colnames(SocialMarket)[head(o5,5)]
o6 = order(loadings[,6], decreasing=TRUE)
colnames(SocialMarket)[head(o6,5)]
o7 = order(loadings[,7], decreasing=TRUE)
colnames(SocialMarket)[head(o7,5)]
```

The first market segment is parents with children who go to school, are religious, have interest in food and are sports fans. These are your average parents who can be targeted better by advertising the product as a sports drink for their kids. The second market segment is the exact same as the first. Hence, we remove the repetition. The third market segment is people into politics, travel, computers, news and automotive. These are your typical white collar employees who can be targeted better by advertising the drink as a health drink. The fourth segment is people who are heavily into health, fitness, outdoors, politics and news. These are your regular outdoorsy health conscious people who coud be of any age or any employment. They can again be targeted better by advertising NutrientH2O as a health drink. The fifth segment is people who post about beauty, fashion, cooking, photosharing and shopping. This segment would easily represent both college students as well as married women. They can be targeted better by offering better prices and packaging. The sixth segment is people who post about gaming, playing sports, their colleges, automotives and cooking. This is a very typical yet accurate description of most college students. They can targeted better by advertising the drink as a sports drink and offering better prices as this is a highly price sensitive group. The seventh segment is people who post about automotives, shopping, photo sharing, news and current events. This seems to be quite a generic group combining different kinds of interests. Hence, removing the repeated segment, we get a total of six different market segments as mentioned above that can be targeted better and advertised to in different ways.

\pagebreak