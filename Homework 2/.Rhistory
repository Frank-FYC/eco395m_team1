# Compare out-of-sample predictive performance using KNN
####
# Split into training and testing sets
n = nrow(results)
n_train = round(0.8*n)  # round to nearest integer
n_test = n - n_train
train_cases = sample.int(n, n_train, replace=FALSE)
test_cases = setdiff(1:n, train_cases)
saratoga_train = results[train_cases,]
saratoga_test = results[test_cases,]
#####
# Train/test split
#####
# randomly sample a set of data points to include in the training set
train_ind = sample.int(n, n_train, replace=FALSE)
# Define the training and testing set
D_train = results[train_ind,]
D_test = results[-train_ind,]
X_train = select(D_train, myvars)
D_train
names(D_train)
rmse_k
View(D_train)
X_train = select(D_train, myvars) ##ERROR D_train does not exist
source('C:/Dropbox/Classes/ECO 395M Data mining and statisical learning/eco395m_team_awesome/Homework 2/Question1_Tessie.R', echo=TRUE)
myvars
X_train = select(D_train, c("landValue", "livingArea", "bedrooms", "centralAir_Yes", "bathrooms", "waterfront_Yes", "age", "fuel_electric", "fuel_gas", "fuel_oil", "lotSize", "newConstruction_Yes")) ##ERROR D_train does not exist
X_train = select(D_train,landValue, livingArea, bedrooms, centralAir_Yes, bathrooms, waterfront_Yes, age, fuel_electric, fuel_gas, fuel_oil, lotSize, newConstruction_Yes)
X_train = select(D_train,landValue, livingArea, bedrooms, centralAir_Yes, bathrooms, waterfront_Yes, age, fuel_electric, fuel_gas, fuel_oil, lotSize, newConstruction_Yes)
X_train = select(D_train,landValue)
D_train
view(D_train)
X_train = select(D_train,landValue)
X_train = dlpyr::select(D_train,landValue)
X_train = dplyr::select(D_train,landValue)
X_train = dplyr::select(D_train,myvars)
####
# Compare out-of-sample predictive performance using KNN
####
# Split into training and testing sets
n = nrow(results)
n_train = round(0.8*n)  # round to nearest integer
n_test = n - n_train
train_cases = sample.int(n, n_train, replace=FALSE)
test_cases = setdiff(1:n, train_cases)
saratoga_train = results[train_cases,]
saratoga_test = results[test_cases,]
#####
# Train/test split
#####
# randomly sample a set of data points to include in the training set
train_ind = sample.int(n, n_train, replace=FALSE)
# Define the training and testing set
D_train = results[train_ind,]
D_test = results[-train_ind,]
X_train = dplyr::select(D_train,myvars)
y_train = dplyr::select(D_train, price)
X_test = dplyr::select(D_test, myvars)
y_test = dplyr::select(D_test, price)
# Running KNN
rmse = function(y, ypred) {
sqrt(mean(data.matrix((y - ypred) ^ 2)))
}
# Multiple K values function
knn_max = nrow(X_train)
khat <- c()
for (i in 3:knn_max)
{
knn = knn.reg(
train = X_train,
test = X_test,
y = y_train,
k = i
)
names(knn)
ypred_knn = knn$pred
#####
# Compare the models by RMSE_out
#####
khat[i] = rmse(y_test, ypred_knn)
}
Averagek <- mean(khat)
####
# plot the fit
####
K = c(1:knn_max)
RMSE = (khat)
rmse_k = ggplot() + geom_path(aes(x = K, y = RMSE), color="red") +
geom_path(aes(x = K, y = mean(rmse_vals$V1)), color="green") +
geom_path(aes(x = K, y = mean(rmse_vals$V2)), color="brown") +
geom_path(aes(x = K, y = mean(rmse_vals$V3)), color="purple")+
geom_path(aes(x = K, y = Averagek), color="black")+
theme_bw(base_size = 18)
rmse_k
rmse_k
####
# Compare out-of-sample predictive performance using KNN
####
# Split into training and testing sets
n = nrow(results)
n_train = round(0.8*n)  # round to nearest integer
n_test = n - n_train
train_cases = sample.int(n, n_train, replace=FALSE)
test_cases = setdiff(1:n, train_cases)
saratoga_train = results[train_cases,]
saratoga_test = results[test_cases,]
#####
# Train/test split
#####
# randomly sample a set of data points to include in the training set
train_ind = sample.int(n, n_train, replace=FALSE)
# Define the training and testing set
D_train = results[train_ind,]
D_test = results[-train_ind,]
X_train = dplyr::select(D_train,myvars)
y_train = dplyr::select(D_train, price)
X_test = dplyr::select(D_test, myvars)
y_test = dplyr::select(D_test, price)
# Running KNN
rmse = function(y, ypred) {
sqrt(mean(data.matrix((y - ypred) ^ 2)))
}
# Multiple K values function
knn_max = nrow(X_train)
khat <- c()
for (i in 3:knn_max)
{
knn = knn.reg(
train = X_train,
test = X_test,
y = y_train,
k = i
)
names(knn)
ypred_knn = knn$pred
#####
# Compare the models by RMSE_out
#####
khat[i] = rmse(y_test, ypred_knn)
}
Averagek <- mean(khat)
####
# plot the fit
####
K = c(1:knn_max)
RMSE = (khat)
rmse_k = ggplot() + geom_path(aes(x = K, y = RMSE), color="red") +
geom_path(aes(x = K, y = mean(rmse_vals$V1)), color="green") +
geom_path(aes(x = K, y = mean(rmse_vals$V2)), color="brown") +
geom_path(aes(x = K, y = mean(rmse_vals$V3)), color="purple")+
geom_path(aes(x = K, y = Averagek), color="black")+
theme_bw(base_size = 18)
rmse_k1 = ggplot() + geom_path(aes(x = K, y = RMSE), color="red") +
geom_path(aes(x = K, y = mean(rmse_vals$V1)), color="green") +
geom_path(aes(x = K, y = mean(rmse_vals$V2)), color="brown") +
geom_path(aes(x = K, y = mean(rmse_vals$V3)), color="purple")+
geom_path(aes(x = K, y = Averagek), color="black")+
theme_bw(base_size = 18) +
xlim(0,500)
rmse_k1
rmse_k = ggplot() + geom_path(aes(x = K, y = RMSE), color="red") +
geom_path(aes(x = K, y = mean(rmse_vals$V1)), color="green") +
geom_path(aes(x = K, y = mean(rmse_vals$V2)), color="brown") +
geom_path(aes(x = K, y = mean(rmse_vals$V3)), color="purple")+
geom_path(aes(x = K, y = Averagek), color="black")+
theme_bw(base_size = 18)+
xlim(0,500)
rmse_k
rmse_k = ggplot() + geom_path(aes(x = K, y = RMSE), color="red") +
geom_path(aes(x = K, y = mean(rmse_vals$V1)), color="green") +
geom_path(aes(x = K, y = mean(rmse_vals$V2)), color="brown") +
geom_path(aes(x = K, y = mean(rmse_vals$V3)), color="purple")+
geom_path(aes(x = K, y = Averagek), color="black")+
theme_bw(base_size = 18)
rmse_k
n_train = round(0.8*n)  # round to nearest integer
n_test = n - n_train
train_cases = sample.int(n, n_train, replace=FALSE)
test_cases = setdiff(1:n, train_cases)
saratoga_train = results[train_cases,]
saratoga_test = results[test_cases,]
# fit to this training set
lm_biggerboom = lm(price ~ bedrooms + centralAir + landValue + livingArea + bathrooms + waterfront + lotSize + age +
fuel + newConstruction +
landValue*lotSize + bathrooms*rooms + age*newConstruction +
bedrooms*bathrooms + centralAir*fuel + landValue*waterfront, data=saratoga_train)
coef(lm_biggerboom)
rm(list=ls())
library(MASS) 	## a library of example datasets
library(tidyverse)
library(nnet)  # for multinom
library(mosaic)
options(warn=-1)
brca <- read.csv("./brca.csv")
#####
#First question: are some radiologists more clinically conservative than others in recalling patients, holding patient risk factors equal?
# Second question: when the radiologists at this hospital interpret a mammogram to make a decision on whether to recall the patient, does the data suggest that they should be weighing some clinical risk factors more heavily than they currently are?
rmse = function(y, yhat) {
sqrt( mean( (y - yhat)^2 ) )
}
df_rad13 = subset(brca,radiologist=="radiologist13")
df_rad34 = subset(brca,radiologist=="radiologist34")
df_rad66 = subset(brca,radiologist=="radiologist66")
df_rad89 = subset(brca,radiologist=="radiologist89")
df_rad95 = subset(brca,radiologist=="radiologist95")
probtest = function(a,b){
n = nrow(a)
n_train = round(0.8*n) #take x times n, then round to nearest
n_test = n - n_train #number of n test is n minus n_train
train_ind = sort(sample.int(n, n_train, replace=FALSE)) # randomly sample from n, n_train times, without replacement, then sort
brca_train = select(a[train_ind,],-radiologist)
brca_test = select(a[-train_ind,],-radiologist)
brca.w_test = select(subset(brca,radiologist != b),-radiologist)
# train models: recall
maxit <<- 10000
lm1 <<- glm(recall ~ .-cancer,
data=brca_train,
maxit = maxit)
lm2 <<- glm(recall ~ (.-cancer)^2,
data=brca_train,
maxit = maxit)
# train models: cancer
lm3 <<- glm(cancer ~ recall,
data=brca_train,
maxit = maxit)
lm4 <<- glm(cancer ~ .,
data=brca_train,
maxit = maxit)
lm5 <<- glm(cancer ~ .-recall,
data=brca_train,
maxit = maxit)
lm6 <<- glm(cancer ~ (.-recall)^2,
data=brca_train,
maxit = maxit)
# predict on the specific radiologist testing set
yhat_test1 = predict(lm1,brca_test)
yhat_test2 = predict(lm2,brca_test)
yhat_test1.w = predict(lm1,brca.w_test)
yhat_test2.w = predict(lm2,brca.w_test)
yhat_test3 = predict(lm3,brca_test)
yhat_test4 = predict(lm4,brca_test)
yhat_test5 = predict(lm5,brca_test)
yhat_test6 = predict(lm6,brca_test)
yhat_test3.w = predict(lm3,brca.w_test)
yhat_test4.w = predict(lm4,brca.w_test)
yhat_test5.w = predict(lm5,brca.w_test)
yhat_test6.w = predict(lm6,brca.w_test)
# predict on the other radiologists testing set
rmse = function(y, yhat) {
sqrt( mean( (y - yhat)^2 ) )
}
c(rmse(brca_test$recall, yhat_test1),
rmse(brca_test$recall, yhat_test2),
rmse(brca.w_test$recall, yhat_test1.w),
rmse(brca.w_test$recall, yhat_test2.w),
rmse(brca_test$recall, yhat_test3),
rmse(brca_test$recall, yhat_test4),
rmse(brca_test$recall, yhat_test5),
rmse(brca_test$recall, yhat_test6),
rmse(brca.w_test$recall, yhat_test3.w),
rmse(brca.w_test$recall, yhat_test4.w),
rmse(brca.w_test$recall, yhat_test5.w),
rmse(brca.w_test$recall, yhat_test6.w)
)
}
# radiologist13 radiologist34 radiologist66 radiologist89 radiologist95
rad13 = do(100)*{probtest(df_rad13,"radiologist13")}
rm(list=ls())
library(MASS) 	## a library of example datasets
library(tidyverse)
library(nnet)  # for multinom
library(mosaic)
options(warn=-1)
brca <- read.csv("./brca.csv")
#####
#First question: are some radiologists more clinically conservative than others in recalling patients, holding patient risk factors equal?
# Second question: when the radiologists at this hospital interpret a mammogram to make a decision on whether to recall the patient, does the data suggest that they should be weighing some clinical risk factors more heavily than they currently are?
rmse = function(y, yhat) {
sqrt( mean( (y - yhat)^2 ) )
}
df_rad13 = subset(brca,radiologist=="radiologist13")
df_rad34 = subset(brca,radiologist=="radiologist34")
df_rad66 = subset(brca,radiologist=="radiologist66")
df_rad89 = subset(brca,radiologist=="radiologist89")
df_rad95 = subset(brca,radiologist=="radiologist95")
probtest = function(a,b){
n = nrow(a)
n_train = round(0.8*n) #take x times n, then round to nearest
n_test = n - n_train #number of n test is n minus n_train
train_ind = sort(sample.int(n, n_train, replace=FALSE)) # randomly sample from n, n_train times, without replacement, then sort
brca_train = select(a[train_ind,])
brca_test = select(a[-train_ind,])
brca.w_test = select(subset(brca,radiologist != b))
# train models: recall
maxit <<- 10000
lm1 <<- glm(recall ~ .-cancer,
data=brca_train,
maxit = maxit)
lm2 <<- glm(recall ~ (.-cancer)^2,
data=brca_train,
maxit = maxit)
# train models: cancer
lm3 <<- glm(cancer ~ recall,
data=brca_train,
maxit = maxit)
lm4 <<- glm(cancer ~ .,
data=brca_train,
maxit = maxit)
lm5 <<- glm(cancer ~ .-recall,
data=brca_train,
maxit = maxit)
lm6 <<- glm(cancer ~ (.-recall)^2,
data=brca_train,
maxit = maxit)
# predict on the specific radiologist testing set
yhat_test1 = predict(lm1,brca_test)
yhat_test2 = predict(lm2,brca_test)
yhat_test1.w = predict(lm1,brca.w_test)
yhat_test2.w = predict(lm2,brca.w_test)
yhat_test3 = predict(lm3,brca_test)
yhat_test4 = predict(lm4,brca_test)
yhat_test5 = predict(lm5,brca_test)
yhat_test6 = predict(lm6,brca_test)
yhat_test3.w = predict(lm3,brca.w_test)
yhat_test4.w = predict(lm4,brca.w_test)
yhat_test5.w = predict(lm5,brca.w_test)
yhat_test6.w = predict(lm6,brca.w_test)
# predict on the other radiologists testing set
rmse = function(y, yhat) {
sqrt( mean( (y - yhat)^2 ) )
}
c(rmse(brca_test$recall, yhat_test1),
rmse(brca_test$recall, yhat_test2),
rmse(brca.w_test$recall, yhat_test1.w),
rmse(brca.w_test$recall, yhat_test2.w),
rmse(brca_test$recall, yhat_test3),
rmse(brca_test$recall, yhat_test4),
rmse(brca_test$recall, yhat_test5),
rmse(brca_test$recall, yhat_test6),
rmse(brca.w_test$recall, yhat_test3.w),
rmse(brca.w_test$recall, yhat_test4.w),
rmse(brca.w_test$recall, yhat_test5.w),
rmse(brca.w_test$recall, yhat_test6.w)
)
}
# radiologist13 radiologist34 radiologist66 radiologist89 radiologist95
rad13 = do(100)*{probtest(df_rad13,"radiologist13")}
rm(list=ls())
library(MASS) 	## a library of example datasets
library(tidyverse)
library(nnet)  # for multinom
library(mosaic)
options(warn=-1)
brca <- read.csv("./brca.csv")
#####
#First question: are some radiologists more clinically conservative than others in recalling patients, holding patient risk factors equal?
# Second question: when the radiologists at this hospital interpret a mammogram to make a decision on whether to recall the patient, does the data suggest that they should be weighing some clinical risk factors more heavily than they currently are?
rmse = function(y, yhat) {
sqrt( mean( (y - yhat)^2 ) )
}
df_rad13 = subset(brca,radiologist=="radiologist13")
df_rad34 = subset(brca,radiologist=="radiologist34")
df_rad66 = subset(brca,radiologist=="radiologist66")
df_rad89 = subset(brca,radiologist=="radiologist89")
df_rad95 = subset(brca,radiologist=="radiologist95")
probtest = function(a,b){
n = nrow(a)
n_train = round(0.8*n) #take x times n, then round to nearest
n_test = n - n_train #number of n test is n minus n_train
train_ind = sort(sample.int(n, n_train, replace=FALSE)) # randomly sample from n, n_train times, without replacement, then sort
brca_train = dplyr::select(a[train_ind,],-radiologist)
brca_test = dplyr::select(a[-train_ind,],-radiologist)
brca.w_test = dplyr::select(subset(brca,radiologist != b),-radiologist)
# train models: recall
maxit <<- 10000
lm1 <<- glm(recall ~ .-cancer,
data=brca_train,
maxit = maxit)
lm2 <<- glm(recall ~ (.-cancer)^2,
data=brca_train,
maxit = maxit)
# train models: cancer
lm3 <<- glm(cancer ~ recall,
data=brca_train,
maxit = maxit)
lm4 <<- glm(cancer ~ .,
data=brca_train,
maxit = maxit)
lm5 <<- glm(cancer ~ .-recall,
data=brca_train,
maxit = maxit)
lm6 <<- glm(cancer ~ (.-recall)^2,
data=brca_train,
maxit = maxit)
# predict on the specific radiologist testing set
yhat_test1 = predict(lm1,brca_test)
yhat_test2 = predict(lm2,brca_test)
yhat_test1.w = predict(lm1,brca.w_test)
yhat_test2.w = predict(lm2,brca.w_test)
yhat_test3 = predict(lm3,brca_test)
yhat_test4 = predict(lm4,brca_test)
yhat_test5 = predict(lm5,brca_test)
yhat_test6 = predict(lm6,brca_test)
yhat_test3.w = predict(lm3,brca.w_test)
yhat_test4.w = predict(lm4,brca.w_test)
yhat_test5.w = predict(lm5,brca.w_test)
yhat_test6.w = predict(lm6,brca.w_test)
# predict on the other radiologists testing set
rmse = function(y, yhat) {
sqrt( mean( (y - yhat)^2 ) )
}
c(rmse(brca_test$recall, yhat_test1),
rmse(brca_test$recall, yhat_test2),
rmse(brca.w_test$recall, yhat_test1.w),
rmse(brca.w_test$recall, yhat_test2.w),
rmse(brca_test$recall, yhat_test3),
rmse(brca_test$recall, yhat_test4),
rmse(brca_test$recall, yhat_test5),
rmse(brca_test$recall, yhat_test6),
rmse(brca.w_test$recall, yhat_test3.w),
rmse(brca.w_test$recall, yhat_test4.w),
rmse(brca.w_test$recall, yhat_test5.w),
rmse(brca.w_test$recall, yhat_test6.w)
)
}
# radiologist13 radiologist34 radiologist66 radiologist89 radiologist95
rad13 = do(100)*{probtest(df_rad13,"radiologist13")}
rad34 = do(100)*{probtest(df_rad34,"radiologist34")}
rad66 = do(100)*{probtest(df_rad66,"radiologist66")}
rad89 = do(100)*{
tryCatch({
probtest(df_rad89,"radiologist89")
}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}
rad95 = do(100)*{probtest(df_rad95,"radiologist95")}
superrad = do(100)*{probtest(brca,"")}
df = as.data.frame(
rbind(
colMeans(rad13),
colMeans(rad34),
colMeans(rad66),
colMeans(rad89),
colMeans(rad95),
colMeans(superrad)
)
)
rownames(df) = c("radiologist13","radiologist34","radiologist66","radiologist89","radiologist95","SuperRad")
colnames(df) = c("lm1","lm2","lm1.w","lm2.w","lm3","lm4","lm5","lm6","lm3.w","lm4.w","lm5.w","lm6.w")
df = as.data.frame(t(df))
df$Rad13.compare = (df$radiologist13 - df$SuperRad)
df$Rad34.compare = (df$radiologist34 - df$SuperRad)
df$Rad66.compare = (df$radiologist66 - df$SuperRad)
df$Rad89.compare = (df$radiologist89 - df$SuperRad)
df$Rad95.compare = (df$radiologist95 - df$SuperRad)
df = as.data.frame(t(df))
df2 = df[,c(1,3,2,4,5,9,6,10,7,11,8,12)]
df2 = as.data.frame(t(df2))
# a confusion table to determine the best way to detect cancer
n = nrow(brca)
n_train = round(0.8*n) #take x times n, then round to nearest
n_test = n - n_train #number of n test is n minus n_train
train_ind = sort(sample.int(n, n_train, replace=FALSE)) # randomly sample from n, n_train times, without replacement, then sort
brca_train = brca[train_ind,]
brca_test = brca[-train_ind,]
lm3 <<- glm(cancer ~ recall,
data=brca_train,
maxit = maxit)
lm4 <<- glm(cancer ~ .,
data=brca_train,
maxit = maxit)
lm5 <<- glm(cancer ~ .-recall,
data=brca_train,
maxit = maxit)
lm6 <<- glm(cancer ~ (.-recall)^2,
data=brca_train,
maxit = maxit)
confusion.table = function(x){
probhat_test = predict(x, newdata=brca_test)
yhat_test = ifelse(probhat_test >= 0.1, 1, 0)
table(y=brca_test$cancer, yhat=yhat_test)
}
confusion.table(lm3)
confusion.table(lm4)
confusion.table(lm5)
confusion.table(lm6)
summary(brca)
t(df2)[,c(1,2,3,4)]
t(df2)[,c(1,2,3,4)]
summary(lm3)
summary(lm5)
t(df2)[,c(5,6,7,8,9,10,11,12)]
c.table_lm3 = confusion.table(lm3)
c.table_lm4 = confusion.table(lm4)
c.table_lm5 = confusion.table(lm5)
c.table_lm6 = suppressWarnings(confusion.table(lm6))
print("lm3 Confusion Table")
c.table_lm3
print("lm4 Confusion Table")
c.table_lm4
print("lm5 Confusion Table")
c.table_lm5
print("lm6 Confusion Table")
c.table_lm6
rmse_k = ggplot() + geom_path(aes(x = K, y = RMSE), color="red") +
geom_path(aes(x = K, y = mean(rmse_vals$V1)), color="green") +
geom_path(aes(x = K, y = mean(rmse_vals$V2)), color="brown") +
geom_path(aes(x = K, y = mean(rmse_vals$V3)), color="purple")+
geom_path(aes(x = K, y = Averagek), color="black")+
theme_bw(base_size = 18) +
xlim(0,1000)
rmse_k
RMSE = (khat)
